import boto3
import json
import gzip

S3_BUCKET_NAME = "your-cloudtrail-log-bucket"

s3 = boto3.client("s3")
dynamodb = boto3.resource("dynamodb")
table_name = "IAMThreatLogs"

# Function to check if the table exists
def check_and_create_table():
    existing_tables = dynamodb.meta.client.list_tables()["TableNames"]
    if table_name not in existing_tables:
        dynamodb.create_table(
            TableName=table_name,
            AttributeDefinitions=[{"AttributeName": "eventID", "AttributeType": "S"}],
            KeySchema=[{"AttributeName": "eventID", "KeyType": "HASH"}],
            BillingMode="PAY_PER_REQUEST"
        )
        print(f"Table {table_name} created successfully!")

# Lambda function
def lambda_handler(event, context):
    check_and_create_table()  # Ensure table exists before inserting logs

    print("Received event:", json.dumps(event, indent=4))

    try:
        # Extract S3 object key
        if "Records" in event and len(event["Records"]) > 0 and "s3" in event["Records"][0]:
            bucket_name = event["Records"][0]["s3"]["bucket"]["name"]
            object_key = event["Records"][0]["s3"]["object"]["key"]
        else:
            bucket_name = S3_BUCKET_NAME
            object_key = "AWSLogs/123456789012/CloudTrail/us-east-1/2025/03/06/correct-log-file.json.gz"

        print(f"Fetching file: {object_key} from bucket: {bucket_name}")

        response = s3.get_object(Bucket=bucket_name, Key=object_key)
        log_data = gzip.decompress(response["Body"].read()).decode("utf-8")
        cloudtrail_events = json.loads(log_data)["Records"]

        table = dynamodb.Table(table_name)
        for log in cloudtrail_events:
            log["eventID"] = log.get("eventID", "unknown")  # Ensure primary key exists
            table.put_item(Item=log)

        return {"status": "IAM logs stored in DynamoDB"}

    except Exception as e:
        print(f"Error processing event: {e}")
        return {"status": "Error processing event", "error": str(e)}